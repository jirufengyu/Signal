{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600224544894",
   "display_name": "Python 3.8.5 64-bit ('tf2py3': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "success\n"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf1\n",
    "import tensorflow.keras as keras\n",
    "import math\n",
    "tf1.disable_eager_execution()\n",
    "class RBM(object):\n",
    "    def __init__(self,input_size,output_size,learning_rate=1.0):\n",
    "        self._input_size=input_size\n",
    "        self._output_size=output_size\n",
    "        self.w=np.zeros([input_size,output_size],np.float32)\n",
    "        self.hb=np.zeros([output_size],np.float32)\n",
    "        self.vb=np.zeros([input_size],np.float32)\n",
    "\n",
    "        self.learning_rate=learning_rate\n",
    "    # Fits the result from the weighted visible layer plus the bias into a sigmoid curve\n",
    "    def prob_h_given_v(self, visible, w, hb):\n",
    "        # Sigmoid\n",
    "        return tf.math.sigmoid(tf.linalg.matmul(visible, w) + hb)\n",
    "     # Fits the result from the weighted hidden layer plus the bias into a sigmoid curve\n",
    "    def prob_v_given_h(self, hidden, w, vb):\n",
    "        return tf.math.sigmoid(tf.linalg.matmul(hidden, tf.transpose(w)) + vb)\n",
    "    def sample_prob(self,probs):\n",
    "        return tf.nn.relu(tf.sign(probs-tf.random.uniform(tf.shape(probs))))\n",
    "    def train(self,X,epochs=2,batchsize=128):\n",
    "        _w=tf1.placeholder(\"float\",[self._input_size,self._output_size])\n",
    "        _hb=tf1.placeholder(\"float\",[self._output_size])\n",
    "        _vb=tf1.placeholder(\"float\",[self._input_size])\n",
    "\n",
    "        prv_w=np.zeros([self._input_size,self._output_size],np.float32)\n",
    "        prv_hb=np.zeros([self._output_size],np.float32)\n",
    "        prv_vb=np.zeros([self._input_size],np.float32)\n",
    "\n",
    "        cur_w=np.zeros([self._input_size,self._output_size],np.float32)\n",
    "        cur_hb=np.zeros([self._output_size],np.float32)\n",
    "        cur_vb=np.zeros([self._input_size],np.float32)\n",
    "        v0=tf1.placeholder(\"float\",[None,self._input_size])\n",
    "\n",
    "        h0=self.sample_prob(self.prob_h_given_v(v0,_w,_hb))\n",
    "        v1=self.sample_prob(self.prob_v_given_h(h0,_w,_vb))\n",
    "        h1=self.prob_h_given_v(v1,_w,_hb)\n",
    "\n",
    "        positive_grad=tf.linalg.matmul(tf.transpose(v0),h0)\n",
    "        negative_grad=tf.linalg.matmul(tf.transpose(v1),h1)\n",
    "\n",
    "        update_w=_w+self.learning_rate*(positive_grad-negative_grad)/tf.cast(tf.shape(v0)[0],dtype=tf.float32)\n",
    "        update_vb=_vb+self.learning_rate*tf.reduce_mean(v0-v1,0)\n",
    "        update_hb=_hb+self.learning_rate*tf.reduce_mean(h0-h1,0)\n",
    "\n",
    "        err=tf.reduce_mean(tf.square(v0-v1))\n",
    "\n",
    "        with tf1.Session() as sess:\n",
    "            sess.run(tf1.global_variables_initializer())\n",
    "            for epoch in range(epochs):\n",
    "                for start,end in zip(range(0,len(X),batchsize),range(batchsize,len(X),batchsize)):\n",
    "                    batch=X[start:end]\n",
    "                    cur_w  = sess.run(update_w,  feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    cur_hb = sess.run(update_hb, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    cur_vb = sess.run(update_vb, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    prv_w=cur_w\n",
    "                    prv_hb=cur_hb\n",
    "                    prv_vb=cur_vb\n",
    "                error=sess.run(err,feed_dict={v0:X,_w: cur_w, _vb: cur_vb, _hb: cur_hb})\n",
    "\n",
    "\n",
    "                print('Epoch: %d' % epoch, 'reconstruction error: %f' % error)\n",
    "\n",
    "            self.w=prv_w\n",
    "            self.hb=prv_hb\n",
    "            self.vb=prv_vb\n",
    "    \n",
    "    def rbm_outpt(self, X):\n",
    "        input_X = tf.constant(X,dtype=tf.float32)\n",
    "        _w = tf.constant(self.w)\n",
    "        _hb = tf.constant(self.hb)\n",
    "        out = tf.math.sigmoid(tf.linalg.matmul(input_X, _w) + _hb)\n",
    "        with tf1.Session() as sess:\n",
    "            sess.run(tf1.global_variables_initializer())\n",
    "            return sess.run(out)\n",
    "\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "#rbm=RBM(784,500)\n",
    "#print(train_images[0])\n",
    "train_images=train_images.reshape(-1,784)\n",
    "train_images=train_images/255.0\n",
    "#print(\"new:\",train_images[0])\n",
    "#rbm.train(train_images)\n",
    "#print(rbm.rbm_outpt(train_images[:10]))\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RBM:  0   784 -> 500\nRBM:  1   500 -> 200\nRBM:  2   200 -> 50\nNew RBM:\nEpoch: 0 reconstruction error: 0.064268\nEpoch: 1 reconstruction error: 0.054660\nNew RBM:\nEpoch: 0 reconstruction error: 0.031731\nEpoch: 1 reconstruction error: 0.028690\nNew RBM:\nEpoch: 0 reconstruction error: 0.065925\nEpoch: 1 reconstruction error: 0.062902\n"
    }
   ],
   "source": [
    "\n",
    "'''训练每一个RBM'''\n",
    "RBM_hidden_sizes = [500, 200 , 50 ] #create 4 layers of RBM with size 785-500-200-50\n",
    "\n",
    "#Since we are training, set input as training data\n",
    "inpX = train_images\n",
    "\n",
    "#Create list to hold our RBMs\n",
    "rbm_list = []\n",
    "\n",
    "#Size of inputs is the number of inputs in the training set\n",
    "input_size = inpX.shape[1]\n",
    "#with tf.device('/gpu:0'):\n",
    "#For each RBM we want to generate\n",
    "for i, size in enumerate(RBM_hidden_sizes):\n",
    "    print('RBM: ',i,' ',input_size,'->', size)\n",
    "    rbm_list.append(RBM(input_size, size))\n",
    "    input_size = size\n",
    "#For each RBM in our list\n",
    "for rbm in rbm_list:\n",
    "    print('New RBM:')\n",
    "    #Train a new one\n",
    "    rbm.train(inpX) \n",
    "    #Return the output layer\n",
    "    inpX = rbm.rbm_outpt(inpX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(object):\n",
    "\n",
    "    def __init__(self, sizes, X, Y):\n",
    "        # Initialize hyperparameters\n",
    "        self._sizes = sizes\n",
    "        self._X = X\n",
    "        self._Y = Y\n",
    "        self.w_list = []\n",
    "        self.b_list = []\n",
    "        self._learning_rate = 1.0\n",
    "        self._momentum = 0.0\n",
    "        self._epoches = 10\n",
    "        self._batchsize = 100\n",
    "        input_size = X.shape[1]\n",
    "\n",
    "        # initialization loop\n",
    "        for size in self._sizes + [Y.shape[1]]:\n",
    "            # Define upper limit for the uniform distribution range\n",
    "            max_range = 4 * math.sqrt(6. / (input_size + size))\n",
    "\n",
    "            # Initialize weights through a random uniform distribution\n",
    "            self.w_list.append(\n",
    "                np.random.uniform(-max_range, max_range, [input_size, size]).astype(np.float32))\n",
    "\n",
    "            # Initialize bias as zeroes\n",
    "            self.b_list.append(np.zeros([size], np.float32))\n",
    "            input_size = size\n",
    "\n",
    "    # load data from rbm\n",
    "    def load_from_rbms(self, dbn_sizes, rbm_list):\n",
    "        # Check if expected sizes are correct\n",
    "        assert len(dbn_sizes) == len(self._sizes)\n",
    "\n",
    "        for i in range(len(self._sizes)):\n",
    "            # Check if for each RBN the expected sizes are correct\n",
    "            assert dbn_sizes[i] == self._sizes[i]\n",
    "\n",
    "        # If everything is correct, bring over the weights and biases\n",
    "        for i in range(len(self._sizes)):\n",
    "            self.w_list[i] = rbm_list[i].w\n",
    "            self.b_list[i] = rbm_list[i].hb\n",
    "\n",
    "    # Training method\n",
    "    def train(self):\n",
    "        # Create placeholders for input, weights, biases, output\n",
    "        _a = [None] * (len(self._sizes) + 2)\n",
    "        _w = [None] * (len(self._sizes) + 1)\n",
    "        _b = [None] * (len(self._sizes) + 1)\n",
    "        _a[0] = tf1.placeholder(\"float\", [None, self._X.shape[1]])\n",
    "        y = tf1.placeholder(\"float\", [None, self._Y.shape[1]])\n",
    "\n",
    "        # Define variables and activation functoin\n",
    "        for i in range(len(self._sizes) + 1):\n",
    "            _w[i] = tf1.Variable(self.w_list[i])\n",
    "            _b[i] = tf1.Variable(self.b_list[i])\n",
    "        for i in range(1, len(self._sizes) + 2):\n",
    "            _a[i] = tf.math.sigmoid(tf.linalg.matmul(_a[i - 1], _w[i - 1]) + _b[i - 1])\n",
    "\n",
    "        # Define the cost function\n",
    "        cost = tf.reduce_mean(tf.square(_a[-1] - y))\n",
    "\n",
    "        # Define the training operation (Momentum Optimizer minimizing the Cost function)\n",
    "        train_op = tf1.train.MomentumOptimizer(\n",
    "            self._learning_rate, self._momentum).minimize(cost)\n",
    "\n",
    "        # Prediction operation\n",
    "        predict_op = tf.argmax(_a[-1], 1)\n",
    "\n",
    "        # Training Loop\n",
    "        with tf1.Session() as sess:\n",
    "            # Initialize Variables\n",
    "            sess.run(tf1.global_variables_initializer())\n",
    "\n",
    "            # For each epoch\n",
    "            for i in range(self._epoches):\n",
    "\n",
    "                # For each step\n",
    "                for start, end in zip(\n",
    "                        range(0, len(self._X), self._batchsize), range(self._batchsize, len(self._X), self._batchsize)):\n",
    "                    # Run the training operation on the input data\n",
    "                    sess.run(train_op, feed_dict={\n",
    "                        _a[0]: self._X[start:end], y: self._Y[start:end]})\n",
    "                    t=sess.run(_a[-1])\n",
    "                    print(t.shape)\n",
    "\n",
    "                for j in range(len(self._sizes) + 1):\n",
    "                    # Retrieve weights and biases\n",
    "                    self.w_list[j] = sess.run(_w[j])\n",
    "                    self.b_list[j] = sess.run(_b[j])\n",
    "\n",
    "                print(\"Accuracy rating for epoch \" + str(i) + \": \" + str(np.mean(np.argmax(self._Y, axis=1) == \\\n",
    "                                                                                 sess.run(predict_op, feed_dict={_a[0]: self._X, y: self._Y}))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(60000, 784)\n(60000, 10)\n"
    }
   ],
   "source": [
    "trX,trY=train_images, train_labels\n",
    "trY=np.eye(10)[trY]\n",
    "print(trX.shape)\n",
    "print(trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation Variable_16/IsInitialized/VarIsInitializedOp: node Variable_16/IsInitialized/VarIsInitializedOp (defined at <ipython-input-16-e85014418ee1>:54)  was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[Variable_16/IsInitialized/VarIsInitializedOp]]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf2py3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2py3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "\u001b[0;32m~/anaconda3/envs/tf2py3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation Variable_16/IsInitialized/VarIsInitializedOp: {{node Variable_16/IsInitialized/VarIsInitializedOp}} was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[Variable_16/IsInitialized/VarIsInitializedOp]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3f24f8a6bf66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRBM_hidden_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_rbms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRBM_hidden_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrbm_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-e85014418ee1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# Initialize Variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;31m# For each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2py3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    958\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2py3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1181\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2py3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1359\u001b[0m                            run_metadata)\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2py3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation Variable_16/IsInitialized/VarIsInitializedOp: node Variable_16/IsInitialized/VarIsInitializedOp (defined at <ipython-input-16-e85014418ee1>:54)  was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[Variable_16/IsInitialized/VarIsInitializedOp]]"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    nNet = NN(RBM_hidden_sizes, trX, trY)\n",
    "    nNet.load_from_rbms(RBM_hidden_sizes,rbm_list)\n",
    "    nNet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}