{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599800528462",
   "display_name": "Python 3.7.7 64-bit ('tf2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "title  \\\n0      深圳地铁将设立ＶＩＰ头等车厢　买双倍票可享坐票   \n1  中国西部是地球上主要干旱带之一，妇女是当地劳动力．．．   \n2              思源焦点公益基金救助孩子：永康   \n3       康师傅回应转卖废弃茶叶：下家承诺用废料做枕头   \n4                        活动时间：   \n\n                                             content  \n0  南都讯　记者刘凡　周昌和　任笑一　继推出日票后，深圳今后将设地铁ＶＩＰ头等车厢，设坐票制。昨...  \n1  同心县地处宁夏中部干旱带的核心区，　冬寒长，春暖迟，夏热短，秋凉早，干旱少雨，蒸发强烈，风大...  \n2  不满一岁的永康是个饱经病痛折磨的孩子，２０１１年７月５日出生的他，患有先天性心脏病、疝气，一...  \n3  就废弃茶叶被转手事件发声明本报讯（记者刘俊）　“我们也是受害者！”昨日，有媒体报道称康师傅...  \n4  ·奖励办法：率先提交的前１００个创意项目，经评估，可优先资助实施。·咨询电话：０１０－６７...  \n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dt=pd.read_csv(\"sgnewfull.csv\",sep='\\t',skiprows=1,names=['title','content'])\n",
    "print(dt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import keras\n",
    "max_features=10000\n",
    "maxlen=300\n",
    "dt=pd.read_csv(\"sgnew.csv\",sep='\\t',skiprows=1,names=['title','content'])\n",
    "def fenci(selist):\n",
    "    #stopwords = read_file(\"stopwords.dat\")#读取停用词\n",
    "    l=[]\n",
    "    for i in selist:\n",
    "\n",
    "        seg_list = jieba.cut(i)  # 默认是精确模式\n",
    "        outstr=''\n",
    "        for word in seg_list:  #去除停顿词\n",
    "            #if word not in stopwords:  #如果去除停用词的话，把注释去掉，同时把下面三行加tab\n",
    "            if word != '\\t':  \n",
    "                outstr += word \n",
    "                outstr += \" \"  \n",
    "        l.append(outstr.strip())\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[2902 2134   37 ... 2878   12 2879]\n [ 498    1  546 ...   39 1217   27]\n [   0    0    0 ...   12 1439   27]\n ...\n [   8 9121 9122 ...  142    3   11]\n [   0    0    0 ...  174  236    3]\n [   0    0    0 ...  895 2431    3]]\n[[2122, 924, 7, 5, 4442, 283, 237, 12, 927, 1167, 660, 9163], [666, 9164, 2149, 196, 48, 2941, 39, 52, 2, 129, 16, 2150, 1426, 26, 1410, 27], [9165, 26, 334, 9166, 27, 26, 17, 27, 1435, 10, 1218, 11, 1719, 1720], [2965, 4089, 8, 1129, 12, 939, 1056, 397, 1222, 25, 9167], [946, 947, 9168, 2990, 9169, 1061, 17, 5, 113, 2992, 2994, 26, 9170, 27]]\n"
    }
   ],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=max_features,lower=True)\n",
    "dt['title']=dt['title'].fillna(\"\")\n",
    "dt['content']=dt['content'].fillna(\"\")\n",
    "content=fenci(list(dt['content']))\n",
    "title=fenci(list(dt['title']))\n",
    "tokenizer.fit_on_texts(content + \n",
    "                       title)\n",
    "\n",
    "content=tokenizer.texts_to_sequences(content)\n",
    "content=keras.preprocessing.sequence.pad_sequences(content,maxlen=maxlen) # padding\n",
    "title=tokenizer.texts_to_sequences(title)\n",
    "print(content)\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}